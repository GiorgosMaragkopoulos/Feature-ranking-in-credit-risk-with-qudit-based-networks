{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# This Notebook illustrates how to run an efficient multilayer QNN, in pytorch, with feature ranking\n",
        "\n"
      ],
      "metadata": {
        "id": "jSjLz7hIYfcM"
      },
      "id": "jSjLz7hIYfcM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "CpD7xEjfdQzi"
      },
      "id": "CpD7xEjfdQzi"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler ,MinMaxScaler , Normalizer\n",
        "from torch.nn.functional import normalize\n",
        "from torch.utils.data import Dataset, DataLoader , TensorDataset\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "isDvyWchY-GS"
      },
      "id": "isDvyWchY-GS",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import taiwan data"
      ],
      "metadata": {
        "id": "LDpzi9I5dSyS"
      },
      "id": "LDpzi9I5dSyS"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://archive.ics.uci.edu/static/public/350/default+of+credit+card+clients.zip\n",
        "!unzip default*"
      ],
      "metadata": {
        "id": "M0mi2Y6JE4HB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d9db8c7-ae0c-4966-d168-dfc9de57e95a"
      },
      "id": "M0mi2Y6JE4HB",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-19 14:18:53--  http://archive.ics.uci.edu/static/public/350/default+of+credit+card+clients.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘default+of+credit+card+clients.zip.1’\n",
            "\n",
            "default+of+credit+c     [   <=>              ]   5.28M  11.0MB/s    in 0.5s    \n",
            "\n",
            "2025-11-19 14:18:54 (11.0 MB/s) - ‘default+of+credit+card+clients.zip.1’ saved [5539494]\n",
            "\n",
            "Archive:  default of credit card clients.xls\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "note:  default of credit card clients.xls may be a plain executable, not an archive\n",
            "unzip:  cannot find zipfile directory in one of default of credit card clients.xls or\n",
            "        default of credit card clients.xls.zip, and cannot find default of credit card clients.xls.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5e923d74",
      "metadata": {
        "id": "5e923d74"
      },
      "outputs": [],
      "source": [
        "# Load the file directly into a NumPy array\n",
        "data = pd.read_excel(\"/content/default of credit card clients.xls\", header=1)\n",
        "data = data.drop(columns=[\"ID\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We need to split and scale the data\n",
        "\n"
      ],
      "metadata": {
        "id": "7uQ8B4VGYyUC"
      },
      "id": "7uQ8B4VGYyUC"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "22379740",
      "metadata": {
        "id": "22379740"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PowerTransformer, QuantileTransformer\n",
        "np.random.seed(32)\n",
        "\n",
        "X = data.drop(columns=[\"default payment next month\"])  # All columns except target\n",
        "y = data[\"default payment next month\"]  # Target column\n",
        "\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.3333, random_state=42, stratify=y_temp)\n",
        "\n",
        "pt = PowerTransformer(method=\"yeo-johnson\")\n",
        "X_train = pt.fit_transform(X_train)\n",
        "X_val = pt.transform(X_val)\n",
        "X_test = pt.transform(X_test)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b73877d",
      "metadata": {
        "id": "6b73877d"
      },
      "source": [
        "## Define the QNN class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "63767e71",
      "metadata": {
        "id": "63767e71"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from functools import reduce\n",
        "\n",
        "def get_SU_d_gens(d):\n",
        "    generators = []\n",
        "\n",
        "    # symmetric generators\n",
        "    for j in range(d-1):\n",
        "        for k in range(j+1, d):\n",
        "            gen = torch.zeros(d, d, dtype=torch.complex128)\n",
        "            gen[j, k] = 1\n",
        "            gen[k, j] = 1\n",
        "            generators.append(gen)\n",
        "\n",
        "    # antisymmetric generators\n",
        "    for j in range(d-1):\n",
        "        for k in range(j+1, d):\n",
        "            gen = torch.zeros(d, d, dtype=torch.complex128)\n",
        "            gen[j, k] = -1j\n",
        "            gen[k, j] = 1j\n",
        "            generators.append(gen)\n",
        "\n",
        "    # diagonal generators\n",
        "    for l in range(1, d):\n",
        "        gen = torch.zeros(d, d, dtype=torch.complex128)\n",
        "        constant = math.sqrt(2/((l * (l+1))))\n",
        "        for j in range(l):\n",
        "            gen[j, j] = constant\n",
        "        gen[l, l] = -constant*l\n",
        "        generators.append(gen)\n",
        "\n",
        "    return generators\n",
        "\n",
        "class QNN(nn.Module):\n",
        "    def __init__(self, qudit_dim, layers):\n",
        "        torch.manual_seed(1234)\n",
        "        super(QNN, self).__init__()\n",
        "        self.d = qudit_dim\n",
        "        self.layers = layers\n",
        "        self.gens = torch.zeros(self.d**2 - 1 - 1, 1, self.d, self.d, dtype=torch.complex128)\n",
        "        _gens = get_SU_d_gens(self.d)\n",
        "        for i in range(self.d**2 - 1 - 1):\n",
        "            self.gens[i,:,:,:] = _gens[i]\n",
        "        self.qudit0 = torch.zeros(self.d, dtype=torch.complex128)\n",
        "        self.qudit0[0] = 1\n",
        "        self.num_gens = 23 #len(self.gens)\n",
        "        self.num_params = self.num_gens * self.layers\n",
        "        self.weights = nn.Parameter(torch.rand(self.num_gens, self.layers, dtype=torch.float64))\n",
        "\n",
        "    def forward(self, x):\n",
        "            weights_m = self.weights\n",
        "            thetas = x.unsqueeze(1) * weights_m.t().unsqueeze(0)\n",
        "            thetas = 2 * torch.atan(2*thetas)\n",
        "            gensWithWeights = thetas[:, :, :, None, None] * self.gens[None, None, :, 0, :, :]\n",
        "            hermitianMatrix = gensWithWeights.sum(dim=2)\n",
        "            unitaryMatrix = torch.matrix_exp(1j * hermitianMatrix)\n",
        "            # finalUnitary = torch.prod(unitaryMatrix, dim=1)\n",
        "            finalUnitary = reduce(torch.bmm, [unitaryMatrix[:,i] for i in range(unitaryMatrix.shape[1])])\n",
        "            results = torch.matmul(finalUnitary, self.qudit0)\n",
        "            probalityVector = torch.abs(results)**2\n",
        "            sums = torch.sum(probalityVector, dim=1).view(-1, 1)\n",
        "            return probalityVector.real / sums.real\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "l7HMYiiEd7PC"
      },
      "id": "l7HMYiiEd7PC"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bd623e45",
      "metadata": {
        "id": "bd623e45"
      },
      "outputs": [],
      "source": [
        "num_layers = 8\n",
        "qnn_model = QNN(5, num_layers)\n",
        "\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.RMSprop(qnn_model.parameters(), lr=0.003)\n",
        "\n",
        "\n",
        "# Define the number of epochs\n",
        "num_epochs = 100\n",
        "\n",
        "# Create DataLoader for batch processing\n",
        "batch_size = 4\n",
        "\n",
        "\n",
        "labels = np.eye(5)[y_train.values]\n",
        "\n",
        "\n",
        "dataset_train = TensorDataset(torch.tensor(X_train_scaled) , torch.tensor(labels) )\n",
        "data_loader_train = DataLoader(dataset_train,batch_size= batch_size,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "81dcec6e",
      "metadata": {
        "id": "81dcec6e"
      },
      "outputs": [],
      "source": [
        "labels_test = np.eye(5)[y_test.values]\n",
        "\n",
        "dataset_test = TensorDataset(torch.tensor(X_test_scaled) , torch.tensor(labels_test) )\n",
        "data_loader_test = DataLoader(dataset_test,batch_size= batch_size,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_val = np.eye(5)[y_val.values]\n",
        "\n",
        "dataset_val = TensorDataset(torch.tensor(X_val_scaled), torch.tensor(labels_val))\n",
        "data_loader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "LabgJhnuiLeq"
      },
      "id": "LabgJhnuiLeq",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f82a4e75",
      "metadata": {
        "id": "f82a4e75"
      },
      "source": [
        "# Ridge Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4431bc93",
      "metadata": {
        "id": "4431bc93",
        "outputId": "f2c9beaf-809a-4b61-b4fb-578e812f2bcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   1/100, Train Loss: 1.2333, Val Loss: 1.1495 Inc Streak: 0\n",
            "Epoch   2/100, Train Loss: 1.1359, Val Loss: 1.1247 Inc Streak: 0\n",
            "Epoch   3/100, Train Loss: 1.1200, Val Loss: 1.1119 Inc Streak: 0\n",
            "Epoch   4/100, Train Loss: 1.1132, Val Loss: 1.1065 Inc Streak: 0\n",
            "Epoch   5/100, Train Loss: 1.1099, Val Loss: 1.1080 Inc Streak: 1\n",
            "Epoch   6/100, Train Loss: 1.1068, Val Loss: 1.1131 Inc Streak: 2\n",
            "Epoch   7/100, Train Loss: 1.1056, Val Loss: 1.0999 Inc Streak: 0\n",
            "Epoch   8/100, Train Loss: 1.1033, Val Loss: 1.0985 Inc Streak: 0\n",
            "Epoch   9/100, Train Loss: 1.1022, Val Loss: 1.1018 Inc Streak: 1\n",
            "Epoch  10/100, Train Loss: 1.1012, Val Loss: 1.1014 Inc Streak: 2\n",
            "Epoch  11/100, Train Loss: 1.1009, Val Loss: 1.0961 Inc Streak: 0\n",
            "Epoch  12/100, Train Loss: 1.0997, Val Loss: 1.0998 Inc Streak: 1\n",
            "Epoch  13/100, Train Loss: 1.0987, Val Loss: 1.0951 Inc Streak: 0\n",
            "Epoch  14/100, Train Loss: 1.0976, Val Loss: 1.0949 Inc Streak: 0\n",
            "Epoch  15/100, Train Loss: 1.0963, Val Loss: 1.0943 Inc Streak: 0\n",
            "Epoch  16/100, Train Loss: 1.0963, Val Loss: 1.0948 Inc Streak: 1\n",
            "Epoch  17/100, Train Loss: 1.0957, Val Loss: 1.0917 Inc Streak: 0\n",
            "Epoch  18/100, Train Loss: 1.0957, Val Loss: 1.0960 Inc Streak: 1\n",
            "Epoch  19/100, Train Loss: 1.0955, Val Loss: 1.0933 Inc Streak: 2\n",
            "Epoch  20/100, Train Loss: 1.0953, Val Loss: 1.0938 Inc Streak: 3\n",
            "Epoch  21/100, Train Loss: 1.0953, Val Loss: 1.0929 Inc Streak: 4\n"
          ]
        }
      ],
      "source": [
        "# Set the L1 regularization strength (lambda)\n",
        "lambda_l1 = 0.00001\n",
        "\n",
        "training_threshold = 0.0002\n",
        "\n",
        "prev_loss = torch.inf\n",
        "no_decr = 0\n",
        "epoch_threshold = 5\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    qnn_model.train()\n",
        "    total_loss = 0.0\n",
        "    for inputs, labels in data_loader_train:\n",
        "\n",
        "        threshold = 3.14\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = qnn_model(inputs)\n",
        "\n",
        "        # Compute the primary loss\n",
        "        labels = labels.to(float)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Add L1 regularization loss\n",
        "        l1_loss = 0.0\n",
        "        for param in qnn_model.parameters():\n",
        "            l1_loss += torch.sum(torch.abs(param))  # Sum of absolute values of weights\n",
        "        loss += lambda_l1 * l1_loss  # Add L1 penalty to the primary loss\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Print the average loss for each epoch\n",
        "    average_loss = total_loss / len(data_loader_train)\n",
        "    # print(f'Epoch {epoch + 1:3d}/{num_epochs}, Loss: {average_loss}')\n",
        "\n",
        "    qnn_model.eval()\n",
        "    val_loss_total = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_inputs, val_labels in data_loader_val:\n",
        "            val_outputs = qnn_model(val_inputs)\n",
        "            val_labels = val_labels.to(torch.float)\n",
        "            val_loss = criterion(val_outputs, val_labels)\n",
        "            val_loss_total += val_loss.item()\n",
        "\n",
        "    average_val_loss = val_loss_total / len(data_loader_val)\n",
        "\n",
        "    if average_val_loss + training_threshold > prev_loss:\n",
        "        no_decr += 1\n",
        "        if no_decr == epoch_threshold:\n",
        "            qnn_model.load_state_dict(torch.load('model_weights.pth'))\n",
        "            break\n",
        "    else:\n",
        "        torch.save(qnn_model.state_dict(), 'model_weights.pth')\n",
        "        no_decr = 0\n",
        "        prev_loss = average_val_loss\n",
        "\n",
        "\n",
        "    print(f'Epoch {epoch + 1:3d}/{num_epochs}, '\n",
        "          f'Train Loss: {average_loss:.4f}, '\n",
        "          f'Val Loss: {average_val_loss:.4f} '\n",
        "          f'Inc Streak: {no_decr}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get classification results\n"
      ],
      "metadata": {
        "id": "c_ontCaieLDZ"
      },
      "id": "c_ontCaieLDZ"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5b89e9e9",
      "metadata": {
        "id": "5b89e9e9"
      },
      "outputs": [],
      "source": [
        "qnn_model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "all_predictions = []  # To store all predictions\n",
        "all_labels = []       # To store all actual labels\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels_test in data_loader_test:\n",
        "        outputs = qnn_model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)  # Get the predicted class indices\n",
        "\n",
        "        # Collect predictions and labels\n",
        "        all_predictions.extend(predicted.cpu().numpy())  # Convert to numpy array and append\n",
        "        all_labels.extend(labels_test.argmax(dim=1).cpu().numpy())  # Convert labels to numpy and append"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ffde9a82",
      "metadata": {
        "id": "ffde9a82"
      },
      "outputs": [],
      "source": [
        "predictions_series = pd.Series(all_predictions)\n",
        "labels_series = pd.Series(all_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "671ed275",
      "metadata": {
        "id": "671ed275"
      },
      "outputs": [],
      "source": [
        "predictions_series = predictions_series.clip(upper=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "de7a1205",
      "metadata": {
        "id": "de7a1205",
        "outputId": "e5b5f451-0245-4434-fbaa-8805b77309fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.95      0.89      5841\n",
            "           1       0.67      0.34      0.45      1659\n",
            "\n",
            "    accuracy                           0.82      7500\n",
            "   macro avg       0.75      0.65      0.67      7500\n",
            "weighted avg       0.80      0.82      0.79      7500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "report = classification_report(labels_series, predictions_series)\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe46e080",
      "metadata": {
        "id": "fe46e080"
      },
      "source": [
        "## Print Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "25b2f990",
      "metadata": {
        "id": "25b2f990",
        "outputId": "ad6d25f3-01d6-42b8-853f-0a925eefb31c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Row Importance Hierarchy:\n",
            "\n",
            "      Layer  Row  Importance (Abs Sum)\n",
            "12  weights   12             14.610908\n",
            "11  weights   11             11.822640\n",
            "13  weights   13             10.382094\n",
            "5   weights    5              7.002505\n",
            "16  weights   16              5.702730\n",
            "14  weights   14              4.097071\n",
            "15  weights   15              3.203190\n",
            "6   weights    6              3.100895\n",
            "9   weights    9              2.120900\n",
            "7   weights    7              1.572244\n",
            "10  weights   10              1.510757\n",
            "17  weights   17              0.856733\n",
            "8   weights    8              0.802849\n",
            "18  weights   18              0.544407\n",
            "0   weights    0              0.419195\n",
            "22  weights   22              0.406064\n",
            "2   weights    2              0.359030\n",
            "3   weights    3              0.330887\n",
            "19  weights   19              0.288909\n",
            "20  weights   20              0.265638\n",
            "21  weights   21              0.208332\n",
            "4   weights    4              0.112168\n",
            "1   weights    1              0.046573\n"
          ]
        }
      ],
      "source": [
        "# Prepare a dictionary to store parameter row sums\n",
        "row_importance_dict = {}\n",
        "\n",
        "# Iterate through model parameters\n",
        "for name, param in qnn_model.named_parameters():\n",
        "    # Compute the sum of absolute values for each row\n",
        "    row_sums = param.data.abs().sum(dim=1).tolist()  # Sum absolute values across columns\n",
        "    row_importance_dict[name] = row_sums\n",
        "\n",
        "# Convert the dictionary to a Pandas DataFrame for better readability\n",
        "importance_df = pd.DataFrame([\n",
        "    {\"Layer\": name, \"Row\": i, \"Importance (Abs Sum)\": row_sum}\n",
        "    for name, row_sums in row_importance_dict.items()\n",
        "    for i, row_sum in enumerate(row_sums)\n",
        "])\n",
        "\n",
        "# Sort by importance\n",
        "importance_df = importance_df.sort_values(by=\"Importance (Abs Sum)\", ascending=False)\n",
        "\n",
        "# Display the importance hierarchy\n",
        "print(\"\\nRow Importance Hierarchy:\\n\")\n",
        "print(importance_df)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}