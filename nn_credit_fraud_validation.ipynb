{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "M0mi2Y6JE4HB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0mi2Y6JE4HB",
        "outputId": "2a5556ea-e411-466f-889e-bec3f8653e57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'creditcard.csv': No such file or directory\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 87.9M  100 87.9M    0     0  39.9M      0  0:00:02  0:00:02 --:--:-- 39.9M\n",
            "Archive:  a.zip\n",
            "  inflating: creditcard.csv          \n"
          ]
        }
      ],
      "source": [
        "#!wget https://gist.githubusercontent.com/lazaros05/a536628fe1f626e0573743|1d2237b7cc/raw/63696c866a4a64569f814ceca2ab26b3d44bbe0c/BC_cardiotox_clinical_variables.csv\n",
        "!rm creditcard.csv\n",
        "!curl https://gist.githubusercontent.com/lazaros05/7a5d126c8c65b0b083a7146bc886f543/raw/8703c449d7913ac406f412e1b74dea6a85287422/creditcard.b64 | base64 -d > a.zip\n",
        "!unzip a.zip\n",
        "!sed -i 's/\"0\"/0/g' creditcard.csv\n",
        "!sed -i 's/\"1\"/1/g' creditcard.csv\n",
        "# !pip install -U imbalanced-learn==0.10.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the file directly into a NumPy array\n",
        "_data = pd.read_csv(\"creditcard.csv\",sep=',', header=0, decimal=\".\")\n",
        "_data.drop_duplicates(inplace=True)\n",
        "\n",
        "def process_column(col):\n",
        "    dataset_1_col = col.astype(str).str.split(',').str[0].astype(float)\n",
        "    dataset_2_col = col.astype(str).str.replace(',', '.', regex=False).astype(float)\n",
        "    return dataset_1_col, dataset_2_col\n",
        "\n",
        "dataset_2 = pd.DataFrame()\n",
        "\n",
        "# Choose columns that contain comma-like values\n",
        "target_columns = [col for col in _data.columns if _data[col].astype(str).str.contains(',').any()]\n",
        "\n",
        "for col in target_columns:\n",
        "    col1, col2 = process_column(_data[col])\n",
        "    dataset_2[col] = col2\n",
        "for col in dataset_2.columns:\n",
        "    _data[col] = dataset_2[col]\n",
        "_data = _data.fillna(0)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Assuming your DataFrame is called `data`\n",
        "\n",
        "# 1. Drop the `ID` column\n",
        "# _data = _data.drop(columns=[\"ID\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import PowerTransformer, QuantileTransformer\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler ,MinMaxScaler , Normalizer\n",
        "from torch.nn.functional import normalize\n",
        "from torch.utils.data import Dataset, DataLoader , TensorDataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from functools import reduce\n",
        "import builtins\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score ,confusion_matrix,classification_report\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "import xgboost as xgb\n",
        "\n",
        "import joblib\n",
        "\n",
        "import time"
      ],
      "metadata": {
        "id": "HUb_jTW7WnwT"
      },
      "id": "HUb_jTW7WnwT",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b91wosO60Lfa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b91wosO60Lfa",
        "outputId": "b13dff01-7570-49d9-b263-2c2e56d43c02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class\n",
            "0    56651\n",
            "1       95\n",
            "Name: count, dtype: int64\n",
            "Class\n",
            "0    28326\n",
            "1       47\n",
            "Name: count, dtype: int64\n",
            "Class\n",
            "0    198276\n",
            "1     19827\n",
            "Name: count, dtype: int64\n",
            "4833\n",
            "Epoch   1/100, Train Loss: 0.3050, Val Loss: 0.1115 Inc Streak: 0\n",
            "Time taken: 150.93 seconds\n",
            "Epoch   2/100, Train Loss: 0.3050, Val Loss: 0.0978 Inc Streak: 0\n",
            "Time taken: 154.86 seconds\n",
            "Epoch   3/100, Train Loss: 0.3050, Val Loss: 0.0883 Inc Streak: 0\n",
            "Time taken: 153.61 seconds\n",
            "Epoch   4/100, Train Loss: 0.3050, Val Loss: 0.0965 Inc Streak: 1\n",
            "Time taken: 151.62 seconds\n",
            "Epoch   5/100, Train Loss: 0.3050, Val Loss: 0.0967 Inc Streak: 2\n",
            "Time taken: 155.83 seconds\n",
            "Epoch   6/100, Train Loss: 0.3050, Val Loss: 0.0911 Inc Streak: 3\n",
            "Time taken: 155.72 seconds\n",
            "Epoch   7/100, Train Loss: 0.3050, Val Loss: 0.0954 Inc Streak: 4\n",
            "Time taken: 152.12 seconds\n",
            "Epoch   8/100, Train Loss: 0.3050, Val Loss: 0.1073 Inc Streak: 5\n",
            "---Stopping training---\n",
            "Accuracy on the training set: 99.83%\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "  seed = 0\n",
        "\n",
        "  data = _data.copy()\n",
        "\n",
        "  # data poisoning\n",
        "  np.random.seed(32 + seed)\n",
        "  num_columns = data.shape[1] - 1\n",
        "  random_indices = np.random.choice(range(num_columns), size=10, replace=False)\n",
        "  for idx in random_indices:\n",
        "    data.iloc[:, idx] = np.random.normal(loc=0, scale=1, size=len(data))\n",
        "  # indices\n",
        "  all_indices = set(range(num_columns))  # All possible column indices except the last one\n",
        "  non_random_indices = sorted(all_indices - set(random_indices))\n",
        "  # scaling/split\n",
        "  X = data.drop('Class',axis=1)\n",
        "  y = data['Class']\n",
        "\n",
        "  X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.125, random_state=42, stratify=y_temp)\n",
        "\n",
        "  scaler_X = MinMaxScaler(feature_range=(0,1))\n",
        "  X_train = scaler_X.fit_transform(X_train)\n",
        "  X_val  = scaler_X.transform(X_val)\n",
        "  X_test  = scaler_X.transform(X_test)\n",
        "  joblib.dump(scaler_X,f'Scaling.joblib')\n",
        "  smote = SMOTE(random_state=42,sampling_strategy=0.1) #minority is 0.3 from majority\n",
        "  X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "  pt = PowerTransformer(method=\"yeo-johnson\")\n",
        "  X_train = pt.fit_transform(X_train)\n",
        "  X_val = pt.transform(X_val)\n",
        "  X_test = pt.transform(X_test)\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "  X_train_scaled = scaler.fit_transform(X_train)\n",
        "  X_val_scaled = scaler.transform(X_val)\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "  print(y_test.value_counts())\n",
        "  print(y_val.value_counts())\n",
        "  print(y_train.value_counts())\n",
        "\n",
        "  # quantum model definitions\n",
        "\n",
        "  class BinaryClassifierFRAUD(nn.Module):\n",
        "      def __init__(self, input_dim):\n",
        "          torch.manual_seed(1234 + seed)\n",
        "          super(BinaryClassifierFRAUD, self).__init__()\n",
        "          # self.net = nn.Sequential(\n",
        "          #     nn.Linear(input_dim, 16),\n",
        "          #     nn.ReLU(),\n",
        "          #     nn.Linear(16, 8),\n",
        "          #     nn.ReLU(),\n",
        "          #     nn.Linear(8, 1)  # output raw logits (no sigmoid)\n",
        "          # )\n",
        "          self.net = nn.Sequential(\n",
        "              nn.Linear(input_dim, 32),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(32, 32),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(32, 32),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(32, 32),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(32, 16),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(16, 8),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(8, 1)  # output raw logits (no sigmoid)\n",
        "          )\n",
        "\n",
        "      def forward(self, x):\n",
        "          return self.net(x)\n",
        "\n",
        "  # prepare for training\n",
        "  nn_model = BinaryClassifierFRAUD(30)\n",
        "  print(sum(p.numel() for p in nn_model.parameters() if p.requires_grad))\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  optimizer = optim.Adam(nn_model.parameters(), lr=0.01)\n",
        "  num_epochs = 100\n",
        "  batch_size = 4\n",
        "  # labels = np.eye(6)[y_train.values]\n",
        "  labels = y_train.values\n",
        "  dataset_train = TensorDataset(torch.tensor(X_train_scaled) , torch.tensor(labels))\n",
        "  data_loader_train = DataLoader(dataset_train,batch_size= batch_size,shuffle=True)\n",
        "  # labels_test = np.eye(6)[y_test.values]\n",
        "  labels_test = y_test.values\n",
        "  dataset_test = TensorDataset(torch.tensor(X_test_scaled) , torch.tensor(labels_test) )\n",
        "  data_loader_test = DataLoader(dataset_test,batch_size= batch_size,shuffle=True)\n",
        "  labels_val = y_val.values\n",
        "  dataset_val = TensorDataset(torch.tensor(X_val_scaled), torch.tensor(labels_val))\n",
        "  data_loader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)\n",
        "  # training\n",
        "  # Set the L1 regularization strength (lambda)\n",
        "  lambda_l1 = 0.00001\n",
        "  training_threshold = 0.0002\n",
        "  prev_loss = torch.inf\n",
        "  no_decr = 0\n",
        "  epoch_threshold = 5\n",
        "  # Training loop\n",
        "  val_loss_list = list()\n",
        "  train_loss_list = list()\n",
        "  for epoch in range(num_epochs):\n",
        "      start_time = time.perf_counter()\n",
        "      nn_model.train()\n",
        "      total_loss = 0.0\n",
        "      for inputs, labels in data_loader_train:\n",
        "          optimizer.zero_grad()\n",
        "          # Forward pass\n",
        "          outputs = nn_model(inputs.float())\n",
        "          # Compute the primary loss\n",
        "          labels = labels.to(float)\n",
        "          labels = labels.view(-1, 1)\n",
        "          # print(outputs)\n",
        "          # print(labels)\n",
        "          loss = criterion(outputs, labels)\n",
        "          # Add L1 regularization loss\n",
        "          l1_loss = 0.0\n",
        "          for param in nn_model.parameters():\n",
        "              l1_loss += torch.sum(torch.abs(param))  # Sum of absolute values of weights\n",
        "          # loss += lambda_l1 * l1_loss  # Add L1 penalty to the primary loss\n",
        "          # Backward pass\n",
        "          loss.backward()\n",
        "          # Update weights\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "      # Print the average loss for each epoch\n",
        "      average_loss = total_loss / len(data_loader_train)\n",
        "      # print(f'Epoch {epoch + 1:3d}/{num_epochs}, Loss: {average_loss}')\n",
        "      nn_model.eval()\n",
        "      val_loss_total = 0.0\n",
        "      with torch.no_grad():\n",
        "          for val_inputs, val_labels in data_loader_val:\n",
        "              val_outputs = nn_model(val_inputs.float())\n",
        "              val_labels = val_labels.to(torch.float)\n",
        "              val_labels = val_labels.view(-1, 1)\n",
        "              val_loss = criterion(val_outputs, val_labels)\n",
        "              val_loss_total += val_loss.item()\n",
        "      average_val_loss = val_loss_total / len(data_loader_val)\n",
        "      if average_val_loss + training_threshold > prev_loss:\n",
        "          no_decr += 1\n",
        "          if no_decr == epoch_threshold:\n",
        "              nn_model.load_state_dict(torch.load(str(seed) + 'model_weights.pth'))\n",
        "              print(f'Epoch {epoch + 1:3d}/{num_epochs}, '\n",
        "                    f'Train Loss: {average_loss:.4f}, '\n",
        "                    f'Val Loss: {average_val_loss:.4f} '\n",
        "                    f'Inc Streak: {no_decr}')\n",
        "              print('---Stopping training---')\n",
        "              val_loss_list.append(average_val_loss)\n",
        "              train_loss_list.append(average_loss)\n",
        "              break\n",
        "      else:\n",
        "          torch.save(nn_model.state_dict(), str(seed) + 'model_weights.pth')\n",
        "          no_decr = 0\n",
        "          prev_loss = average_val_loss\n",
        "      print(f'Epoch {epoch + 1:3d}/{num_epochs}, '\n",
        "            f'Train Loss: {average_loss:.4f}, '\n",
        "            f'Val Loss: {average_val_loss:.4f} '\n",
        "            f'Inc Streak: {no_decr}')\n",
        "      val_loss_list.append(average_val_loss)\n",
        "      train_loss_list.append(average_loss)\n",
        "      end_time = time.perf_counter()\n",
        "      print(f'Time taken: {end_time - start_time:.2f} seconds')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # evaluate quantum model\n",
        "  nn_model.eval() # Set the model to evaluation mode\n",
        "  correct_predictions = 0\n",
        "  total_samples =0\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in data_loader_test:\n",
        "      outputs = torch.sigmoid(nn_model(inputs.float()).float())\n",
        "      # _, predicted = torch.max(outputs,1)\n",
        "      predicted = (outputs > 0.5).float()\n",
        "      total_samples += labels.size(0)\n",
        "      correct_predictions += (predicted.squeeze() == labels).sum().item()\n",
        "      # correct_predictions += (predicted == labels.argmax(dim=1)).sum().item()\n",
        "  accuracy = correct_predictions / total_samples\n",
        "  nn_results = (accuracy,)\n",
        "  print(f'Accuracy on the training set: {accuracy*100:.2f}%')\n",
        "  nn_model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "  all_predictions = []  # To store all predictions\n",
        "  all_labels = []       # To store all actual labels\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels_test in data_loader_test:\n",
        "          # outputs = nn_model(inputs.float())\n",
        "          outputs = torch.sigmoid(nn_model(inputs.float()).float())\n",
        "          # _, predicted = torch.max(outputs, 1)  # Get the predicted class indices\n",
        "          predicted = (outputs > 0.5).float()\n",
        "          # Collect predictions and labels\n",
        "          all_predictions.extend(predicted.squeeze().cpu().numpy())  # Convert to numpy array and append\n",
        "          # all_labels.extend(labels_test.argmax(dim=1).cpu().numpy())  # Convert labels to numpy and append\n",
        "          all_labels.extend(labels_test.cpu().numpy())  # Convert labels to numpy and append\n",
        "  # classification report\n",
        "\n",
        "\n",
        "  predictions_series = pd.Series(all_predictions)\n",
        "  labels_series = pd.Series(all_labels)\n",
        "  predictions_series = predictions_series.clip(upper=1)\n",
        "  report = classification_report(labels_series, predictions_series)\n",
        "  nn_results = nn_results + (classification_report(labels_series, predictions_series, output_dict=True),)\n",
        "  print(\"\\nClassification Report:\\n\")\n",
        "  print(report)\n",
        "  # feature importance of quantum\n",
        "  # Prepare a dictionary to store parameter row sums\n",
        "  nn_results = nn_results + ((0, 0),)\n",
        "  nn_results = nn_results + ((train_loss_list, val_loss_list,),)\n",
        "\n",
        "  results = ((\"logistic_regression_results\",),) + ((nn_results,),) + ((\"rf_results\",),)\n",
        "\n",
        "\n",
        "  # nn_dict = {\n",
        "  #     # '% of matched features' : [results[i][1][0][2][0] for i in range(len(seeds))],\n",
        "  #     # 'weight sum/diff score' : [results[i][1][0][2][1] for i in range(len(seeds))],\n",
        "  #     'class 0, precision' : [results[i][1][0][1]['0']['precision'] for i in range(len(seeds))],\n",
        "  #     'class 0, recall' : [results[i][1][0][1]['0']['recall'] for i in range(len(seeds))],\n",
        "  #     'class 0, f1-score' : [results[i][1][0][1]['0']['f1-score'] for i in range(len(seeds))],\n",
        "  #     'class 0, support' : [results[i][1][0][1]['0']['support'] for i in range(len(seeds))],\n",
        "  #     'class 1, precision': [results[i][1][0][1]['1']['precision'] for i in range(len(seeds))],\n",
        "  #     'class 1, recall': [results[i][1][0][1]['1']['recall'] for i in range(len(seeds))],\n",
        "  #     'class 1, f1-score': [results[i][1][0][1]['1']['f1-score'] for i in range(len(seeds))],\n",
        "  #     'class 1, support': [results[i][1][0][1]['1']['support'] for i in range(len(seeds))],\n",
        "  #     'accuracy': [results[i][1][0][1]['accuracy'] for i in range(len(seeds))],\n",
        "  #     'macro avg precision': [results[i][1][0][1]['macro avg']['precision'] for i in range(len(seeds))],\n",
        "  #     'macro avg recall': [results[i][1][0][1]['macro avg']['recall'] for i in range(len(seeds))],\n",
        "  #     'macro avg f1-score': [results[i][1][0][1]['macro avg']['f1-score'] for i in range(len(seeds))],\n",
        "  #     'macro avg support': [results[i][1][0][1]['macro avg']['support'] for i in range(len(seeds))],\n",
        "  #     'weighted avg precision': [results[i][1][0][1]['weighted avg']['precision'] for i in range(len(seeds))],\n",
        "  #     'weighted avg recall': [results[i][1][0][1]['weighted avg']['recall'] for i in range(len(seeds))],\n",
        "  #     'weighted avg f1-score': [results[i][1][0][1]['weighted avg']['f1-score'] for i in range(len(seeds))],\n",
        "  #     'weighted avg support': [results[i][1][0][1]['weighted avg']['support'] for i in range(len(seeds))],\n",
        "  #     'train_loss' : [results[i][1][0][3][0] for i in range(len(seeds))],\n",
        "  #     'val_loss' : [results[i][1][0][3][1] for i in range(len(seeds))]\n",
        "  # }\n",
        "\n",
        "  # # lr_dt = pd.DataFrame(lr_dict)\n",
        "  # # rf_dt = pd.DataFrame(rf_dict)\n",
        "  # nn_dt = pd.DataFrame(nn_dict)\n",
        "\n",
        "  # # lr_dt.to_csv(\"lr_fraud.csv\")\n",
        "  # # rf_dt.to_csv(\"rf_fraud.csv\")\n",
        "  # nn_dt.to_csv(\"nn_fraud.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eBh9UxiowWjh",
      "metadata": {
        "id": "eBh9UxiowWjh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}